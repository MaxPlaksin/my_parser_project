import telebot
import pandas as pd
import re
import os
import logging
from mail_watcher import run_scheduled_check

# === –õ–û–ì–ì–ò–†–û–í–ê–ù–ò–ï ===
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.FileHandler("bot_log.log"), logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# === –ù–ê–°–¢–†–û–ô–ö–ò ===
TELEGRAM_TOKEN = '7136103155:AAHS8y4z7CsdSpddDddU6p60TM8dTFElXmY'
HTML_FILE = '–¥–ª—è –±–æ—Ç–∞ (HTML4).html'

bot = telebot.TeleBot(TELEGRAM_TOKEN)


def normalize(text):
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö —á–∏—Å–ª–æ–≤—ã—Ö –∞—Ä—Ç–∏–∫—É–ª–æ–≤"""
    if pd.isna(text):
        return ''
    text = str(text).strip()
    text = text.replace('\xa0', '').replace('\u202f', '')
    # –î–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ü–∏—Ñ—Ä—ã
    text = re.sub(r'[^\d]', '', text)
    if text.endswith('.0'):
        text = text[:-2]
    return text.lower()


def normalize_with_spaces(text):
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø—Ä–æ–±–µ–ª–æ–≤ –¥–ª—è —Å–æ—Å—Ç–∞–≤–Ω—ã—Ö –∞—Ä—Ç–∏–∫—É–ª–æ–≤"""
    if pd.isna(text):
        return ''
    text = str(text).strip()
    text = text.replace('\xa0', ' ').replace('\u202f', ' ')
    # –ó–∞–º–µ–Ω—è–µ–º –≤—Å–µ –Ω–µ—Ü–∏—Ñ—Ä–æ–≤—ã–µ —Å–∏–º–≤–æ–ª—ã (–∫—Ä–æ–º–µ –ø—Ä–æ–±–µ–ª–æ–≤) –Ω–∞ –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r'[^\d\s]', ' ', text)
    # –ó–∞–º–µ–Ω—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –Ω–∞ –æ–¥–∏–Ω –ø—Ä–æ–±–µ–ª
    text = re.sub(r'\s+', ' ', text)
    text = text.strip()
    return text.lower()


def safe_get(row, col, default='‚Äî'):
    val = row.get(col, default)
    return default if str(val).lower() in ['nan', 'none', ''] else val


def load_database():
    try:
        logger.info(f"üìÇ –ó–∞–≥—Ä—É–∂–∞—é HTML-—Ñ–∞–π–ª {HTML_FILE}...")
        if not os.path.exists(HTML_FILE):
            logger.error(f"–§–∞–π–ª {HTML_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
            return None

        tables = pd.read_html(HTML_FILE)
        df_local = tables[0]

        df_local.columns = df_local.iloc[0].map(str).str.strip()
        df_local = df_local.iloc[1:].reset_index(drop=True)
        df_local = df_local.astype(str)

        # –°–æ–∑–¥–∞–µ–º –¥–≤–∞ —Å—Ç–æ–ª–±—Ü–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞: –æ–¥–∏–Ω –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∞—Ä—Ç–∏–∫—É–ª–æ–≤, –¥—Ä—É–≥–æ–π –¥–ª—è —Å–æ—Å—Ç–∞–≤–Ω—ã—Ö
        df_local['–ê—Ä—Ç–∏–∫—É–ª_clean'] = df_local['–ê—Ä—Ç–∏–∫—É–ª'].apply(normalize)
        df_local['–ê—Ä—Ç–∏–∫—É–ª_with_spaces'] = df_local['–ê—Ä—Ç–∏–∫—É–ª'].apply(normalize_with_spaces)

        logger.info(f"‚úÖ –ë–∞–∑–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ó–∞–ø–∏—Å–µ–π: {len(df_local)}")
        return df_local
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –±–∞–∑—ã: {e}")
        return None


def find_best_matches(user_input, df_data):
    if df_data is None:
        return "‚ö†Ô∏è –ë–∞–∑–∞ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ /reload –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."

    try:
        # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: —Ä–∞–∑–±–∏–≤–∞–µ–º –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ —Å—Ç—Ä–æ–∫–∏
        # –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–æ–∫—É –æ—Ç–¥–µ–ª—å–Ω–æ
        lines = user_input.split('\n')
        all_potential_compound_articles = []
        all_potential_simple_articles = []

        for line in lines:
            # 1. –ò—â–µ–º —Å–æ—Å—Ç–∞–≤–Ω—ã–µ –∞—Ä—Ç–∏–∫—É–ª—ã (–≥—Ä—É–ø–ø—ã —Ü–∏—Ñ—Ä, —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª–∞–º–∏)
            # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ 2-4 –≥—Ä—É–ø–ø —Ü–∏—Ñ—Ä, —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–∞–º–∏
            compound_pattern = r'\b\d{2,5}(?:\s+\d{1,5}){1,3}\b'
            potential_compound_articles = re.findall(compound_pattern, line)
            all_potential_compound_articles.extend(potential_compound_articles)

            # 2. –ò—â–µ–º –ø—Ä–æ—Å—Ç—ã–µ —á–∏—Å–ª–æ–≤—ã–µ –∞—Ä—Ç–∏–∫—É–ª—ã (–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ü–∏—Ñ—Ä)
            simple_pattern = r'\b\d{4,}\b'
            potential_simple_articles = re.findall(simple_pattern, line)
            all_potential_simple_articles.extend(potential_simple_articles)

        logger.info(f"–ù–∞–π–¥–µ–Ω—ã –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ —Å–æ—Å—Ç–∞–≤–Ω—ã–µ –∞—Ä—Ç–∏–∫—É–ª—ã: {all_potential_compound_articles}")

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–æ—Å—Ç–∞–≤–Ω—ã–µ –∞—Ä—Ç–∏–∫—É–ª—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–æ–±–µ–ª—ã
        normalized_compound_candidates = [normalize_with_spaces(c) for c in all_potential_compound_articles]
        logger.info(f"–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Å–æ—Å—Ç–∞–≤–Ω—ã–µ –∞—Ä—Ç–∏–∫—É–ª—ã: {normalized_compound_candidates}")

        # –ò—Å–∫–ª—é—á–∞–µ–º —á–∞—Å—Ç–∏ —Å–æ—Å—Ç–∞–≤–Ω—ã—Ö –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –∏–∑ –ø—Ä–æ—Å—Ç—ã—Ö
        for compound in all_potential_compound_articles:
            for part in re.findall(r'\d+', compound):
                if part in all_potential_simple_articles:
                    all_potential_simple_articles.remove(part)

        logger.info(f"–ù–∞–π–¥–µ–Ω—ã –ø—Ä–æ—Å—Ç—ã–µ —á–∏—Å–ª–æ–≤—ã–µ –∞—Ä—Ç–∏–∫—É–ª—ã: {all_potential_simple_articles}")

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ—Å—Ç—ã–µ –∞—Ä—Ç–∏–∫—É–ª—ã
        normalized_simple_candidates = [normalize(c) for c in all_potential_simple_articles]
        logger.info(f"–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–æ—Å—Ç—ã–µ –∞—Ä—Ç–∏–∫—É–ª—ã: {normalized_simple_candidates}")

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –∫–∞–Ω–¥–∏–¥–∞—Ç—ã
        all_candidates = normalized_simple_candidates + normalized_compound_candidates

        if not all_candidates:
            return "‚õîÔ∏è –ù–µ –Ω–∞–π–¥–µ–Ω –Ω–∏ –æ–¥–∏–Ω –∞—Ä—Ç–∏–∫—É–ª –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏."

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –≤ –±–∞–∑–µ
        found_rows = pd.DataFrame()
        found_articles = []
        not_found_articles = []

        # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º —Å–æ—Å—Ç–∞–≤–Ω—ã–µ –∞—Ä—Ç–∏–∫—É–ª—ã (—Å—Ç—Ä–æ–≥–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ)
        for candidate in normalized_compound_candidates:
            # –°—Ç—Ä–æ–≥–∏–π –ø–æ–∏—Å–∫ –ø–æ —Ç–æ—á–Ω–æ–º—É —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—é
            matches = df_data[df_data['–ê—Ä—Ç–∏–∫—É–ª_with_spaces'] == candidate]
            if not matches.empty:
                found_rows = pd.concat([found_rows, matches])
                found_articles.append(candidate)
            else:
                not_found_articles.append(candidate)

        # –ó–∞—Ç–µ–º –∏—â–µ–º –ø—Ä–æ—Å—Ç—ã–µ –∞—Ä—Ç–∏–∫—É–ª—ã (—Å—Ç—Ä–æ–≥–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ)
        for candidate in normalized_simple_candidates:
            # –°—Ç—Ä–æ–≥–∏–π –ø–æ–∏—Å–∫ –ø–æ —Ç–æ—á–Ω–æ–º—É —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—é
            matches = df_data[df_data['–ê—Ä—Ç–∏–∫—É–ª_clean'] == candidate]
            if not matches.empty:
                found_rows = pd.concat([found_rows, matches])
                found_articles.append(candidate)
            else:
                not_found_articles.append(candidate)

        logger.info(f"–ù–∞–π–¥–µ–Ω—ã –≤ –±–∞–∑–µ: {found_articles}")
        logger.info(f"–ù–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –±–∞–∑–µ: {not_found_articles}")

        if found_rows.empty:
            return "‚ùå –ù–∏ –æ–¥–∏–Ω –∞—Ä—Ç–∏–∫—É–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –±–∞–∑–µ."

        unique_rows = found_rows.drop_duplicates(subset='–ê—Ä—Ç–∏–∫—É–ª', keep='first')

        results = []
        for _, row in unique_rows.iterrows():
            price = safe_get(row, '–¶–µ–Ω–∞', '')
            currency = safe_get(row, '–í–∞–ª—é—Ç–∞', '')
            price_text = "–Ω–µ—Ç" if price.lower() in ['nan', '', 'none'] else f"{price} {currency}".strip()

            results.append(
                f"üì¶ –ê—Ä—Ç–∏–∫—É–ª: {row['–ê—Ä—Ç–∏–∫—É–ª']}\n"
                f"–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ: {safe_get(row, '–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞')}\n"
                f"–ö–æ–¥: {safe_get(row, '–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞.–ö–æ–¥')}\n"
                f"–°–∫–ª–∞–¥: {safe_get(row, '–°–∫–ª–∞–¥')}\n"
                f"–û—Å—Ç–∞—Ç–æ–∫: {safe_get(row, '–û—Å—Ç–∞—Ç–æ–∫')}\n"
                f"–¶–µ–Ω–∞: {price_text}\n"
            )

        reply = "\n".join(results[:20])
        if len(results) > 20:
            reply += f"\n...–∏ –µ—â—ë {len(results) - 20} –ø–æ–∑–∏—Ü–∏–π"

        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–µ–Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∞—Ä—Ç–∏–∫—É–ª–∞—Ö, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        if not_found_articles:
            reply += f"\n\n‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –±–∞–∑–µ: {', '.join(not_found_articles)}"

        return reply
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {e}")
        return "‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."


@bot.message_handler(commands=['start', 'help'])
def handle_start_help(message):
    help_text = (
        "üîç *–ë–æ—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É (HTML-–±–∞–∑–∞)*\n\n"
        "–û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –∞—Ä—Ç–∏–∫—É–ª —Ç–æ–≤–∞—Ä–∞ ‚Äî –∏ —è –Ω–∞–π–¥—É –µ–≥–æ –≤ –±–∞–∑–µ.\n"
        "–ü—Ä–∏–º–µ—Ä—ã:\n"
        "`805015`\n"
        "`–≥–¥–µ 805015 –∏ 805017`\n"
        "`–∫–æ–¥ 3546945`\n"
        "`3222 3390 07`\n"
        "`3128 0619 00`\n"
    )
    bot.send_message(message.chat.id, help_text, parse_mode='Markdown')


@bot.message_handler(commands=['reload'])
def handle_reload(message):
    global df
    bot.send_message(message.chat.id, "üîÑ –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞—é HTML-–±–∞–∑—É...")
    df = load_database()
    if df is not None:
        bot.send_message(message.chat.id, f"‚úÖ –ë–∞–∑–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –ó–∞–ø–∏—Å–µ–π: {len(df)}")
    else:
        bot.send_message(message.chat.id, "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å HTML-–±–∞–∑—É.")


@bot.message_handler(func=lambda message: True)
def handle_message(message):
    try:
        user_text = message.text
        logger.info(f"–ó–∞–ø—Ä–æ—Å –æ—Ç {message.from_user.id}: {user_text}")
        bot.send_chat_action(message.chat.id, 'typing')
        reply = find_best_matches(user_text, df)

        for i in range(0, len(reply), 4000):
            bot.send_message(message.chat.id, reply[i:i + 4000])

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        bot.send_message(message.chat.id, "‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞.")


if __name__ == "__main__":
    run_scheduled_check()
    df = load_database()
    print("‚úÖ HTML-–±–æ—Ç –∑–∞–ø—É—â–µ–Ω –∏ –∂–¥—ë—Ç –∑–∞–ø—Ä–æ—Å—ã...")
    try:
        bot.polling(non_stop=True, timeout=60, long_polling_timeout=30)
    except Exception as e:
        logger.critical(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –±–æ—Ç–∞: {e}")
